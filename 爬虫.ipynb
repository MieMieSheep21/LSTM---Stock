{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a24ec40-52d6-4217-889e-e0767267468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "def  storeCommentInf(comment):#存储评论\n",
    "    db = pymysql.connect(\"localhost\", \"root\", \"你的密码\", \"dfcf\")\n",
    "    cur=db.cursor()\n",
    "    sql = 'INSERT INTO TB_COMMENT(comment_id,content,like_count,date ,user_id,share_code) values (%(comment_id)s,%(content)s,%(like_count)s,%(date)s,%(user_id)s,%(share_code)s)'\n",
    "    sql1 = 'SELECT * FROM TB_COMMENT where COMMENT_ID=%s'\n",
    "    if  cur.execute(sql1,(comment[\"comment_id\"])):#去重\n",
    "        db.commit()\n",
    "        cur.close()\n",
    "        print(\"评论已经存在\")\n",
    "        db.close()\n",
    "    else:\n",
    "        cur.execute(sql, (comment))\n",
    "        db.commit()\n",
    "        cur.close()\n",
    "        db.close()\n",
    "        print(\"插入评论成功\")\n",
    "\n",
    "\n",
    "def storeUserInf(user):#储存用户数据\n",
    "    db = pymysql.connect(\"localhost\", \"root\", \"你的密码\", \"dfcf\")\n",
    "    cur = db.cursor()\n",
    "    sql = 'INSERT INTO TB_USER(id,fans) values (%(id)s,%(fans)s)'\n",
    "    sql1='SELECT * FROM TB_USER where ID=%s'\n",
    "    if  cur.execute(sql1,(user[\"id\"])):#去重\n",
    "        db.commit()\n",
    "        cur.close()\n",
    "        db.close()\n",
    "        print(\"用户已经存在\")\n",
    "    else:\n",
    "        cur.execute(sql, (user))\n",
    "        db.commit()\n",
    "        cur.close()\n",
    "        db.close()\n",
    "        print(\"插入用户成功\")\n",
    "\n",
    "def selectCommentOrderByDate(share_code,method):#查询评论信息\n",
    "    db = pymysql.connect(\"localhost\", \"root\", \"你的密码\", \"dfcf\")\n",
    "    cur = db.cursor()\n",
    "    if  method==0:#按照日期升序\n",
    "        sql = 'SELECT * FROM TB_COMMENT WHERE SHARE_CODE=%s ORDER BY DATE '\n",
    "    else:#按照日期降序\n",
    "        sql='SELECT * FROM TB_COMMENT WHERE SHARE_CODE=%s ORDER  BY DATE DESC '\n",
    "    cur.execute(sql,(share_code))\n",
    "    db.commit()\n",
    "    cur.close()\n",
    "    return  cur.fetchall()\n",
    "\n",
    "def selectFansByUserId(userId):#查询用户粉丝数\n",
    "    db = pymysql.connect(\"localhost\", \"root\", \"你的密码\", \"dfcf\")\n",
    "    cur = db.cursor()\n",
    "    sql = 'SELECT FANS FROM TB_USER where ID=%s'\n",
    "    cur.execute(sql,userId)\n",
    "    db.commit()\n",
    "    cur.close()\n",
    "    return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccda6fa-5f13-4848-97cb-dee681f49637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4777\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import multiprocessing\n",
    "import sql\n",
    "import time\n",
    "\n",
    "def getHtml(url):#下载网页源代码\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; LCTE; rv:11.0) like Gecko'}\n",
    "    try:\n",
    "        r=requests.get(url,headers=header)\n",
    "        r.encoding='utf-8'\n",
    "        #print(r.status_code)\n",
    "        r.raise_for_status()\n",
    "        return r.text\n",
    "    except:\n",
    "         return getHtml(url)\n",
    "\n",
    "def getDate(commentHtml):#在网页源码中获得评论发表日期，格式：'YY-mm-dd'\n",
    "    soup = BeautifulSoup(commentHtml, \"html.parser\")\n",
    "    if soup.find(\"div\", {\"class\": \"zwfbtime\"})==None:\n",
    "        return None\n",
    "    date = soup.find(\"div\", {\"class\": \"zwfbtime\"}).text\n",
    "    return date[4:14]\n",
    "\n",
    "def getLikeCount(commentHtml):#在网页源码中获得特定评论的点赞人数\n",
    "    soup = BeautifulSoup(commentHtml, \"html.parser\")\n",
    "    if soup.find(\"div\", {\"data-like_count\": True})==None:\n",
    "        return None\n",
    "    likeCount=soup.find(\"div\", {\"data-like_count\": True})\n",
    "    return int(likeCount['data-like_count'])\n",
    "\n",
    "def getUserFans(userHtml):#在网页源码中获得用户粉丝数\n",
    "            soup = BeautifulSoup(userHtml, \"html.parser\")\n",
    "            #print(soup)\n",
    "            if soup.find(\"a\", {\"id\": \"tafansa\"}) == None:\n",
    "                return None\n",
    "            if soup.find(\"a\", {\"id\": \"tafansa\"}).find(\"span\") == None:\n",
    "                return None\n",
    "            fans=soup.find(\"a\", {\"id\": \"tafansa\"}).find(\"span\").text\n",
    "            return int(fans)\n",
    "\n",
    "\n",
    "def getAndStoreInf(html,share_code):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    #print(soup)\n",
    "    contain = soup.find_all(\"div\", {\"class\": \"articleh\"})#获取每条评论节点\n",
    "    for i in contain:\n",
    "        try:\n",
    "            if i.find(\"em\", {\"class\": \"hinfo\"}) == None and i.find(\"em\", {\"class\": \"settop\"}) == None and \"id\" not in i.attrs.keys():#排除公告、新闻等内容\n",
    "                content = i.find(\"span\", {\"class\": \"l3 a3\"}).find(\"a\")\n",
    "                contentUrl=\"http://guba.eastmoney.com\"+content[\"href\"]#内容详情页面\n",
    "                commentId=content[\"href\"][-14:-5]\n",
    "                userUrl = i.find(\"span\", {\"class\": \"l4 a4\"}).find(\"a\").attrs[\"href\"]#用户主页链接\n",
    "                if contentUrl.__contains__(\"qa\") or contentUrl.__contains__(\"cfhpl\"):#排除问答等内容，只保留用户评论\n",
    "                    continue\n",
    "                if userUrl==\"http://guba.eastmoney.com/list,jjdt.html\":#排除基金动态资讯\n",
    "                    continue\n",
    "                text=content.attrs[\"title\"]#获取评论标题。因东方财富网股吧中大部分用户只发表简短的评论，其标题和内容一致，为简化，只爬取标题。\n",
    "                commentHtml=getHtml(contentUrl)\n",
    "                date=getDate(commentHtml)#获取评论发表时间\n",
    "                if date==None:\n",
    "                    continue\n",
    "                likeCount=getLikeCount(commentHtml)#获取评论点赞数量\n",
    "                if likeCount==None:\n",
    "                    continue\n",
    "                userId=userUrl[23:]#获取用户ID\n",
    "                userFans=getUserFans(getHtml(userUrl))#用户粉丝数\n",
    "                if userFans==None:\n",
    "                    continue\n",
    "                comment={\"comment_id\":commentId,\"content\":text,\"like_count\":likeCount,\"date\":date,\"user_id\":userId,\"share_code\":share_code}\n",
    "                user={\"id\":userId,\"fans\":userFans}\n",
    "                #存储到数据库中\n",
    "                sql.storeUserInf(user)\n",
    "                sql.storeCommentInf(comment)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def run(data):\n",
    "        html = getHtml(\"http://guba.eastmoney.com/list,\"+data['share_code']+\",f_\" + str(data['page']) + \".html\")\n",
    "        getAndStoreInf(html,data['share_code'])\n",
    "        print('-------------page-------------'+str(data['page']))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = multiprocessing.Pool(processes=6)#多进程并行爬取，提高爬取速率。但进程不可设置过多，否则会被ban.\n",
    "    for i in range(4777,5400):\n",
    "        print(i)\n",
    "        share_code=[]\n",
    "        for page in range(i*5+1, (i+1)*5):\n",
    "            share_code.append({'share_code':'zssh000001','page':page})\n",
    "        try:\n",
    "            pool.map(run,share_code)\n",
    "        except:\n",
    "            pool.map(run, share_code)\n",
    "        print('-------sleeping-------')\n",
    "        time.sleep(30)#每爬取5个评论列表（约400个评论详情页面和400个用户页面），停止爬取30s，降低被ban的概率\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ee392-2685-481e-bdcc-801ada2d220f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
